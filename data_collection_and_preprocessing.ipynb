{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b678d3f-06d5-4ba0-bdad-02f224668afe",
   "metadata": {},
   "source": [
    "# YouTube Data Analysis\n",
    "\n",
    "The data collection phase involves retrieving comprehensive information from the YouTube API to form a robust dataset for analysis. This includes gathering details about individual videos, channel statistics, and user comments. The API requests provide insights into crucial metrics such as view counts, likes, dislikes, video duration, subscriber counts, and sentiment analysis of comments. The collected data serves as the foundation for subsequent exploratory data analysis (EDA) and insightful visualizations, enabling a thorough understanding of the channel's performance and user engagement patterns.\n",
    "\n",
    "In this notebook, we will focus on the preprocessing of the collected YouTube data to prepare it for analysis. The provided code snippet demonstrates various preprocessing steps, including calculating title character length, converting data types, parsing date and time, extracting features, and deriving new metrics. These preprocessing steps are essential for ensuring the data is in a suitable format for analysis and modeling.\n",
    "\n",
    "The subsequent sections will delve into exploratory data analysis (EDA) and visualizations to gain insights into the performance and engagement patterns of the YouTube channel based on the preprocessed data.\n",
    "\n",
    "Let's dive into the preprocessing steps and uncover valuable insights from the YouTube data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbac5c8-0803-4c99-a522-bb1ff64e1bf5",
   "metadata": {},
   "source": [
    "### Importing libraries üìö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "2fee918b-a40d-4d2f-abc9-6e2bccf14217",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "from itertools import chain\n",
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "import isodate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b04470c-21e4-4d50-bd5c-51d227223073",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Reminder:</b> If necessary, please download the required packages.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2621abe-7ea2-472e-9ad4-4597e9f34cec",
   "metadata": {},
   "source": [
    "\n",
    "### Data Collection üóÇÔ∏è\r\n",
    "\r\n",
    "1. **Connecting to the YouTube API**: Establish a connection to the YouTube API using authentication credentials to access the required data.\r\n",
    "\r\n",
    "2. **Creating Functions to Get Channel Data**: Develop functions to retrieve channel statistics such as subscriber counts, video counts, and other relevant metrics.\r\n",
    "\r\n",
    "3. **Retrieving Video IDs Based on Channel Data**: Utilize the API to fetch video IDs associated with the channel to enable further data retrieval.\r\n",
    "\r\n",
    "4. **Fetching Video Details Based on Video IDs**: Develop functions to gather detailed information about individual videos, including metrics such as vi, countdislikes, and video duration.\r\n",
    "\r\n",
    "5. **Collecting Comments Data from the Videos**: Use API requests to extract user com videos.uired.\r",
    "ns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb10445-03bf-47ad-9524-d68690b10a7c",
   "metadata": {},
   "source": [
    "### Connecting to the YouTube API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a75414-ddce-4a4a-a957-b2bec155020a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Reminder:</b> Fill in the API key.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "b8038d7a-41ad-4e34-a838-395cd3d1074b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Required parameters\n",
    "api_key ='API_KEY'\n",
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\"\n",
    "\n",
    "# Get credentials and create an API client\n",
    "youtube = build(api_service_name, api_version, developerKey=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "df634b1d-aa27-4a49-a9aa-254a1a7d8302",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_ids = ['UCJQJAI7IjbLcpsjWdSzYz0Q', #Thu Vu data analytics\n",
    "               'UC5DNytAJ6_FISueUfzZCVsw', #Code with Ania Kub√≥w\n",
    "               'UCV8e2g4IWQqK71bbzGDEI4Q', #Data Professor\n",
    "               'UCn8ujwUInbJkBhffxqAPBVQ', #Dave Ebbelaar\n",
    "               'UCWr0mx597DnSGLFk1WfvSkQ', #Hallden\n",
    "               'UCcJQ96WlEhJ0Ve0SLmU310Q', #Internet Made Coder\n",
    "               'UCq6XkhO5SZ66N04IcPbqNcw', #Keith Galli\n",
    "               'UCiT9RITQ9PW6BhXK0y2jaeg', #Ken Jee\n",
    "               'UC8wZnXYK_CGKlBcZp-GxYPA', #NeuralNine\n",
    "               'UCxladMszXan-jfgzyeIMyvw', #Rob Mulla\n",
    "               'UC7cs8q-gJRlGwj4A8OmCmXg', #Alex The Analyst\n",
    "               'UC2UXDak6o7rBm23k3Vv5dww', #Tina Huang\n",
    "               'UCtYLUTtgS3k1Fg4y5tAhLbw', #StatQuest with Josh Starmer\n",
    "              ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f9bd06-1b06-4a45-8d62-1cade0d34077",
   "metadata": {},
   "source": [
    "### Functions to retrieve the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "96c92b43-de4f-4e26-b358-426e77e89ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_data(youtube_object, channel_list):\n",
    "    all_data = []\n",
    "    \n",
    "    request = youtube.channels().list(\n",
    "        part=\"snippet,contentDetails,statistics\", \n",
    "        id=','.join(channel_list))\n",
    "\n",
    "    response = request.execute()\n",
    "    \n",
    "    for item in response['items']:\n",
    "        data = {'channelName': item['snippet']['title'],\n",
    "                'totalVidoes': item['statistics']['videoCount'],\n",
    "                'subscribers': item['statistics']['subscriberCount'],\n",
    "                'views': item['statistics']['viewCount'],\n",
    "                'playlistId': item['contentDetails']['relatedPlaylists']['uploads']}\n",
    "        all_data.append(data)\n",
    "        \n",
    "    return(pd.DataFrame(all_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "1ad0fb12-f9c1-43d3-902e-5adc7c609b63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_video_ids(youtube, playlist_id):\n",
    "    \n",
    "    video_ids = []\n",
    "    \n",
    "    request = youtube.playlistItems().list(\n",
    "        part=\"snippet,contentDetails\",\n",
    "        playlistId = playlist_id,\n",
    "        maxResults = 50)\n",
    "    response = request.execute()\n",
    "    \n",
    "    for item in response['items']:\n",
    "        video_ids.append(item['contentDetails']['videoId'])\n",
    "        \n",
    "    next_page_token = response.get('nextPageToken')\n",
    "    while next_page_token is not None:\n",
    "        request = youtube.playlistItems().list(\n",
    "            part='contentDetails',\n",
    "            playlistId = playlist_id,\n",
    "            maxResults = 50,\n",
    "            pageToken = next_page_token)\n",
    "        response = request.execute()\n",
    "    \n",
    "        for item in response['items']:\n",
    "            video_ids.append(item['contentDetails']['videoId'])\n",
    "\n",
    "        next_page_token = response.get('nextPageToken')\n",
    "    return video_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "a177384f-8cee-4982-935f-15d11dcb808e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_video_details(youtube, video_ids):\n",
    "\n",
    "    all_video_info = []\n",
    "\n",
    "    for i in range(0, len(video_ids), 50):\n",
    "        request = youtube.videos().list(\n",
    "            part=\"snippet,contentDetails,statistics\",\n",
    "            id=','.join(video_ids[i:i+50]))\n",
    "        response = request.execute()\n",
    "\n",
    "        for video in response['items']:\n",
    "            stats_to_keep = {'snippet': ['channelTitle', 'title', 'description', 'tags', 'publishedAt'],\n",
    "                             'statistics': ['viewCount', 'likeCount', 'favouriteCount', 'commentCount'],\n",
    "                             'contentDetails': ['duration', 'definition', 'caption']}\n",
    "\n",
    "            video_info = {}\n",
    "            video_info['video_id'] = video['id']\n",
    "\n",
    "            for k in stats_to_keep.keys():\n",
    "                for v in stats_to_keep[k]:\n",
    "                    try:\n",
    "                        video_info[v] = video[k][v]\n",
    "                    except:\n",
    "                        video_info[v] = None\n",
    "\n",
    "            all_video_info.append(video_info)\n",
    "                         \n",
    "    return pd.DataFrame(all_video_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "26c01b76-61e9-47b2-b96a-64e905ff848b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_comments_in_videos(youtube, video_ids):\n",
    "    all_comments = []\n",
    "    \n",
    "    for video_id in video_ids:\n",
    "        try:   \n",
    "            request = youtube.commentThreads().list(\n",
    "                part=\"snippet,replies\",\n",
    "                videoId=video_id\n",
    "            )\n",
    "            response = request.execute()\n",
    "        \n",
    "            comments_in_video = [comment['snippet']['topLevelComment']['snippet']['textOriginal'] for comment in response['items'][0:10]]\n",
    "            comments_in_video_info = {'video_id': video_id, 'comments': comments_in_video}\n",
    "\n",
    "            all_comments.append(comments_in_video_info)\n",
    "            \n",
    "        except: \n",
    "            print('Could not get comments for video ' + video_id)\n",
    "        \n",
    "    return pd.DataFrame(all_comments) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952cbbaa-2425-4d35-8f9a-7fada8120487",
   "metadata": {},
   "source": [
    "### Creating Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "d4fa8f38-e4e4-4814-a8a5-a2121dc4f830",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not get comments for video Kbzr7p2cIbk\n",
      "Could not get comments for video BgxBEKhaqyQ\n",
      "Could not get comments for video dbOWqJxqbXw\n",
      "Could not get comments for video 5IYDMiEyE90\n",
      "Could not get comments for video Tx_cuqfX8a4\n",
      "Could not get comments for video oMBGiUuqyk4\n",
      "Could not get comments for video 8nJvjNnONbY\n"
     ]
    }
   ],
   "source": [
    "channel_df = get_channel_data(youtube, channel_ids)\n",
    "\n",
    "playlist_ids = channel_df['playlistId'].tolist()\n",
    "\n",
    "# empty list\n",
    "video_ids = []\n",
    "\n",
    "for playlist in playlist_ids:\n",
    "    video_ids.append(get_video_ids(youtube, playlist))\n",
    "    \n",
    "video_ids = list(chain.from_iterable(video_ids))\n",
    "\n",
    "video_df = get_video_details(youtube, video_ids)\n",
    "\n",
    "comments_df = get_comments_in_videos(youtube, video_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bf0c8b-9424-4635-80cc-9626403fde7e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Pre-processing ‚öíÔ∏è\n",
    "- The code calculates the length of the 'title' and stores it in a new column 'titleLength'.\r\n",
    "- It converts specific columns ('viewCount', 'likeCount', 'favouriteCount', 'commentCount') to numeric type, handling errors with 'coerce' option.\r\n",
    "- The 'publishedAt' column is converted to a string type and then parsed to datetime format using the dateutil parser.\r\n",
    "- The day name is extracted from the 'publishedAt' column and stored in a new column 'publishDayName'.\r\n",
    "- The duration of the videos is converted to seconds and stored in a new column 'durationSecs'.\r\n",
    "- NaN values in the 'tags' column are filled with 0.\r\n",
    "- The code calculates the likes and comments per 1000 views ratio and stores the results in new columns 'likeRatio' and 'commentRatio', respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b67c212-d9c8-484c-a412-780974183b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Title character length\n",
    "video_df['titleLength'] = video_df['title'].apply(lambda x: len(x))\n",
    "\n",
    "# Convert specified columns to numeric type\n",
    "numeric_cols = ['viewCount', 'likeCount', 'commentCount']\n",
    "video_df[numeric_cols] = video_df[numeric_cols].apply(pd.to_numeric, errors='coerce', axis=1)\n",
    "\n",
    "# Convert 'publishedAt' column to string type\n",
    "video_df['publishedAt'] = video_df['publishedAt'].astype(str)\n",
    "\n",
    "# Parse 'publishedAt' column to datetime format\n",
    "video_df['publishedAt'] = video_df['publishedAt'].apply(lambda x: parser.parse(x))\n",
    "\n",
    "# Extract the day name from the 'publishedAt' column\n",
    "video_df['publishDayName'] = video_df['publishedAt'].apply(lambda x: x.strftime(\"%A\"))\n",
    "\n",
    "# Convert duration to seconds\n",
    "video_df['durationSecs'] = video_df['duration'].apply(lambda x: isodate.parse_duration(x))\n",
    "video_df['durationSecs'] = video_df['durationSecs'].astype('timedelta64[s]')\n",
    "\n",
    "# Convert durationSecs to integer seconds\n",
    "video_df['durationSecs'] = pd.to_timedelta(video_df['durationSecs']).dt.total_seconds().astype(int)\n",
    "\n",
    "# Calculate likes and comments per 1000 views ratio\n",
    "video_df['likeRatio'] = video_df['likeCount'] / video_df['viewCount'] * 1000\n",
    "video_df['commentRatio'] = video_df['commentCount'] / video_df['viewCount'] * 1000\n",
    "\n",
    "# Drops column with all 'NaN' values\n",
    "video_df.dropna(subset = ['favouriteCount'], inplace=True)\n",
    "# Drops rows with viewCount equal to zero\n",
    "video_df = video_df[video_df.viewCount != 0]\n",
    "\n",
    "# Convert durationSecs to minutes\n",
    "video_df['durationMinutes'] = video_df['durationSecs'] / 60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6635f7-9275-4640-b9da-f04c336c3807",
   "metadata": {},
   "source": [
    "### Saving retrieved data to CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8e05fa-4515-4946-8457-e1fbb1c04789",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Reminder:</b> Retrieving data can be time-consuming and resource-intensive. It's advisable to save the retrieved data into CSV files for future use.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "ad571f56-7302-468c-933b-05a65c9dfc2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Saves video data \n",
    "video_df.to_csv('video_data.csv', index=False)\n",
    "\n",
    "# Saves comments data\n",
    "comments_df.to_csv('comments_data.csv', index=False)\n",
    "\n",
    "# Saves channels data\n",
    "channel_df.to_csv('channel_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e152e9a-5198-48cf-a48d-eb6421b1f48f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-panel-2023.05-py310",
   "language": "python",
   "name": "conda-env-anaconda-panel-2023.05-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
